{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "from zeronmt.models.attention import Attention\n",
        "from zeronmt.models.decoder import Decoder\n",
        "from zeronmt.models.encoder import Encoder\n",
        "from zeronmt.models.seq2seq import Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.de.gz', 'train.en.gz')\n",
        "val_urls = ('val.de.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
        "\n",
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
        "\n",
        "de_tokenizer = get_tokenizer('basic_english') # keep it simple\n",
        "en_tokenizer = get_tokenizer('basic_english') # keep it simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_vocab(filepath, tokenizer):\n",
        "  counter = Counter()\n",
        "  with io.open(filepath, encoding=\"utf8\") as f:\n",
        "    for string_ in f:\n",
        "      counter.update(tokenizer(string_))\n",
        "  return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "de_vocab.set_default_index(de_vocab['<unk>'])\n",
        "en_vocab.set_default_index(en_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_process(filepaths):\n",
        "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
        "                            dtype=torch.long)\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                            dtype=torch.long)\n",
        "    data.append((de_tensor_, en_tensor_))\n",
        "  return data\n",
        "\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "test_data = data_process(test_filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAPPING_PATH = Path(\n",
        "    \"/home/maciej/github/bachelor-thesis/project/vecs/le0n8xvt7l/best_mapping.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_DIM = len(de_vocab)\n",
        "OUTPUT_DIM = len(en_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "# TODO we use the same idx for the other language, this is okay assuming special tokens are prepended !!!!!!1 (in fact they are)\n",
        "PAD_IDX = de_vocab[\"<pad>\"]\n",
        "BOS_IDX = de_vocab[\"<bos>\"]\n",
        "EOS_IDX = de_vocab[\"<eos>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2Seq(enc, dec, PAD_IDX=PAD_IDX).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(18757, 32)\n",
              "    (rnn): GRU(32, 64, bidirectional=True)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(10210, 32)\n",
              "    (rnn): GRU(160, 64)\n",
              "    (out): Linear(in_features=224, out_features=10210, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_batch(data_batch):\n",
        "    de_batch, en_batch = [], []\n",
        "    for de_item, en_item in data_batch:\n",
        "        de_batch.append(\n",
        "            torch.cat(\n",
        "                [torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0\n",
        "            )\n",
        "        )\n",
        "        en_batch.append(\n",
        "            torch.cat(\n",
        "                [torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0\n",
        "            )\n",
        "        )\n",
        "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "    return de_batch, en_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dl = DataLoader(\n",
        "    train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dl = DataLoader(\n",
        "    val_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "test_dl = DataLoader(\n",
        "    test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "PAD_IDX = en_vocab['<pad>']\n",
        "\n",
        "PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "  warning_cache.warn(\n",
            "\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | encoder   | Encoder          | 646 K \n",
            "1 | decoder   | Decoder          | 2.7 M \n",
            "2 | criterion | CrossEntropyLoss | 0     \n",
            "-----------------------------------------------\n",
            "3.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.3 M     Total params\n",
            "13.260    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 30. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 6/227 [00:36<22:16,  6.05s/it, v_num=17, train_loss=9.210]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/maciej/.cache/pypoetry/virtualenvs/0nmt-W1lV1jMD-py3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(gradient_clip_val=1.0, max_epochs=10)\n",
        "trainer.fit(\n",
        "    model, train_dataloaders=[train_dl], val_dataloaders=[valid_dl]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO use state dict to serialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open('model', 'wb') as f:\n",
        "#     torch.save(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open('model', 'rb') as f:\n",
        "#     model = torch.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| de_in.shape: torch.Size([5, 1])\n",
            "ic| de_in: tensor([[    2],\n",
            "                   [  175],\n",
            "                   [ 5735],\n",
            "                   [12184],\n",
            "                   [    3]])\n",
            "ic| en_in.shape: torch.Size([5, 1])\n",
            "ic| en_in: tensor([[   2],\n",
            "                   [ 174],\n",
            "                   [4826],\n",
            "                   [7497],\n",
            "                   [   3]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[   2],\n",
              "        [ 174],\n",
              "        [4826],\n",
              "        [7497],\n",
              "        [   3]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "de_in = torch.tensor(\n",
        "    [de_vocab[token] for token in de_tokenizer(\"<bos> ich liebe kartoffeln <eos>\")]\n",
        ").unsqueeze(1)\n",
        "en_in = torch.tensor(\n",
        "    [en_vocab[token] for token in en_tokenizer(\"<bos> i love potatoes <eos>\")]\n",
        ").unsqueeze(\n",
        "    1\n",
        ")  # actually unused\n",
        "ic(de_in.shape)\n",
        "ic(de_in)\n",
        "ic(en_in.shape)\n",
        "ic(en_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_vocab['<bos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| torch.tensor(tuple(en_vocab['<bos>'] for _ in de_in[:, 0])).unsqueeze(-1).shape: torch.Size([5, 1])\n",
            "ic| torch.tensor(tuple(en_vocab['<bos>'] for _ in de_in[:, 0])).unsqueeze(-1): tensor([[2],\n",
            "                                                                                       [2],\n",
            "                                                                                       [2],\n",
            "                                                                                       [2],\n",
            "                                                                                       [2]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2]])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ic(torch.tensor(tuple(en_vocab['<bos>'] for _ in de_in[:, 0])).unsqueeze(-1).shape)\n",
        "ic(torch.tensor(tuple(en_vocab['<bos>'] for _ in de_in[:, 0])).unsqueeze(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| en_in: tensor([[   2],\n",
            "                   [ 174],\n",
            "                   [4826],\n",
            "                   [7497],\n",
            "                   [   3]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[   2],\n",
              "        [ 174],\n",
              "        [4826],\n",
              "        [7497],\n",
              "        [   3]])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_in.shape\n",
        "ic(en_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| output.shape: torch.Size([5, 1, 10210])\n",
            "ic| predicted_tokens.shape: torch.Size([5, 1])\n",
            "ic| predicted_tokens: tensor([[  0],\n",
            "                              [ 21],\n",
            "                              [  5],\n",
            "                              [241],\n",
            "                              [ 17]])\n",
            "ic| [en_vocab.get_itos()[t] for t in predicted_tokens]: ['<unk>', 'a', 'young', 'boy', 'in']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<unk>', 'a', 'young', 'boy', 'in']"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = model(de_in, en_in, teacher_forcing_ratio=0)\n",
        "torch.set_printoptions(profile=\"full\")\n",
        "predicted_tokens = output.argmax(-1)\n",
        "ic(output.shape)\n",
        "ic(predicted_tokens.shape)\n",
        "ic(predicted_tokens)\n",
        "ic([en_vocab.get_itos()[t] for t in predicted_tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| output.shape: torch.Size([5, 1, 10210])\n",
            "ic| predicted_tokens.shape: torch.Size([5, 1])\n",
            "ic| predicted_tokens: tensor([[ 0],\n",
            "                              [ 4],\n",
            "                              [ 5],\n",
            "                              [17],\n",
            "                              [21]])\n",
            "ic| [en_vocab.get_itos()[t] for t in predicted_tokens]: ['<unk>', 'two', 'young', 'in', 'a']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<unk>', 'two', 'young', 'in', 'a']"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = model(de_in, torch.tensor(tuple(en_vocab['<bos>'] for _ in de_in[:, 0])).unsqueeze(-1), teacher_forcing_ratio=0)\n",
        "torch.set_printoptions(profile=\"full\")\n",
        "predicted_tokens = output.argmax(-1)\n",
        "ic(output.shape)\n",
        "ic(predicted_tokens.shape)\n",
        "ic(predicted_tokens)\n",
        "ic([en_vocab.get_itos()[t] for t in predicted_tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<unk>'"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_vocab.get_itos()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_printoptions(threshold=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| de_in.shape: torch.Size([35, 128])\n",
            "ic| en_in.shape: torch.Size([30, 128])\n",
            "ic| de_in.shape: torch.Size([35, 1])\n",
            "ic| en_in.shape: torch.Size([30, 1])\n",
            "ic| de_in[:, 0]: tensor([    2,    48,   127,    86,   427,  2249, 14246,    34,    56,  1115,\n",
            "                             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "                             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "                             1,     1,     1,     1,     1])\n",
            "ic| en_in[:, 0]: tensor([   2,   21,  251,   74,   16,    9, 1100, 1324, 1612,   21,  698,    3,\n",
            "                            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "                            1,    1,    1,    1,    1,    1])\n",
            "ic| output.shape: torch.Size([30, 1, 10210])\n",
            "ic| predicted_tokens.shape: torch.Size([30, 1])\n",
            "ic| predicted_tokens[:, 0]: tensor([  0,  21, 251,  74, 120,   9,  17,  21,  21,  14,  14,   3,   3,  14,\n",
            "                                      3,  14,   3,   3,   3,  14,   3,   3,   3,   3,  14,   3,  14,   3,\n",
            "                                     14,   3])\n",
            "ic| [de_vocab.get_itos()[t] for t in de_in[:12]]: ['<bos>',\n",
            "                                                   'eine',\n",
            "                                                   'gruppe',\n",
            "                                                   'von',\n",
            "                                                   'männern',\n",
            "                                                   'lädt',\n",
            "                                                   'baumwolle',\n",
            "                                                   'auf',\n",
            "                                                   'einen',\n",
            "                                                   'lastwagen',\n",
            "                                                   '<eos>',\n",
            "                                                   '<pad>']\n",
            "ic| [en_vocab.get_itos()[t] for t in predicted_tokens[:12]]: ['<unk>',\n",
            "                                                              'a',\n",
            "                                                              'group',\n",
            "                                                              'of',\n",
            "                                                              'people',\n",
            "                                                              'are',\n",
            "                                                              'in',\n",
            "                                                              'a',\n",
            "                                                              'a',\n",
            "                                                              '.',\n",
            "                                                              '.',\n",
            "                                                              '<eos>']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " 'a',\n",
              " 'group',\n",
              " 'of',\n",
              " 'people',\n",
              " 'are',\n",
              " 'in',\n",
              " 'a',\n",
              " 'a',\n",
              " '.',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for de_in, en_in in valid_dl:\n",
        "    ic(de_in.shape)\n",
        "    ic(en_in.shape)\n",
        "    de_in = de_in[:, 0].unsqueeze(-1) # first item in the batch only\n",
        "    en_in = en_in[:, 0].unsqueeze(-1) # first item in the batch only\n",
        "    ic(de_in.shape)\n",
        "    ic(en_in.shape)\n",
        "    ic(de_in[:, 0])\n",
        "    ic(en_in[:, 0])\n",
        "    break\n",
        "output = model(de_in, en_in, teacher_forcing_ratio=0)\n",
        "torch.set_printoptions(profile=\"full\")\n",
        "predicted_tokens = output.argmax(-1)\n",
        "ic(output.shape)\n",
        "ic(predicted_tokens.shape)\n",
        "ic(predicted_tokens[:, 0]) # get first batch here\n",
        "ic([de_vocab.get_itos()[t] for t in de_in[:12]]) # limit tokens to first 12 for better presentation\n",
        "ic([en_vocab.get_itos()[t] for t in predicted_tokens[:12]]) # limit tokens to first 12 for better presentation\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "0nmt-W1lV1jMD-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
